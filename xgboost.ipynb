{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "raw_data = pd.read_csv('customer.csv')\n",
    "masked_df = pd.read_csv('customer_test_masked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_gas_feature(df):\n",
    "    gas_median = df[df['gas_usage'] > 3].gas_usage.median()\n",
    "\n",
    "    non_bill_cases_values = {\n",
    "        1: gas_median,\n",
    "        2: gas_median,\n",
    "        3: 0\n",
    "    }\n",
    "    non_bill_cases = {\n",
    "        1: 'Included in rent', \n",
    "        2: 'Included in electricity', \n",
    "        3: 'No charge'\n",
    "    }\n",
    "\n",
    "    # New feature for gas usage category\n",
    "    df['gas_category'] = df['gas_usage'].replace(non_bill_cases).where(\n",
    "        df['gas_usage'].isin(non_bill_cases.keys()), 'Actual Bill'\n",
    "    )\n",
    "    df.loc[pd.isna(df['gas_usage']), 'gas_category'] = 'Unknown'\n",
    "\n",
    "    # Replace non-bill cases' values or maintain if not included\n",
    "    df['gas_usage'] = df['gas_usage'].replace(non_bill_cases_values)\n",
    "    df['gas_usage'] = df['gas_usage'].fillna(gas_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = ['state_of_res']\n",
    "categorical_features = ['sex','marital_status', 'housing_type', 'gas_category', 'recent_move_b', 'is_employed'] \n",
    "numerical_features = ['income', 'num_vehicles', 'age', 'gas_usage', 'rooms' ,'age_income']  \n",
    "target_feature = 'health_ins'\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    \n",
    "    df_features = df.drop(target_feature, axis=1)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "            ('label', OrdinalEncoder(), label_features),\n",
    "            ('onehot', OneHotEncoder(drop='first'), categorical_features),\n",
    "            ('scaler', StandardScaler(), numerical_features)        \n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    features_processed = preprocessor.fit_transform(df_features)\n",
    "    \n",
    "    feature_names = label_features + preprocessor.named_transformers_['onehot'].get_feature_names_out(categorical_features).tolist() + numerical_features\n",
    "    \n",
    "    df_processed = pd.DataFrame(features_processed, columns=feature_names)\n",
    "\n",
    "    # Ensure indices align\n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    df_target = df[target_feature].reset_index(drop=True)\n",
    "    \n",
    "    df_processed[target_feature] = df_target\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample_then_split(df, sample_function, params, classifier):\n",
    "    # Preprocess data\n",
    "    preprocessed_df = preprocess_dataframe(df)\n",
    "\n",
    "    X = preprocessed_df.drop(target_feature, axis=1)  \n",
    "    y = preprocessed_df[target_feature]\n",
    "        \n",
    "    # Sample data\n",
    "    X_resampled, y_resampled = sample_function(X, y)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train model with GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=params, cv=5)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering(df):\n",
    "    \n",
    "    df.drop(columns=['Unnamed: 0', 'code_column'], inplace=True)\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    rows_with_missing = df_filtered.isnull().sum(axis=1) > 2\n",
    "    df_filtered.drop(df_filtered[rows_with_missing].index, inplace=True)\n",
    "    \n",
    "    df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
    "    \n",
    "    df_filtered['num_vehicles'] = df_filtered['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].fillna(df_filtered['recent_move_b'].mode()[0])\n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_filtered['age'] = df_filtered['age'].replace(0, df_filtered['age'].median())\n",
    "    rows_with_age_120 = df_filtered['age'] == 120\n",
    "    df_filtered = df_filtered.drop(df_filtered[rows_with_age_120].index)\n",
    "    \n",
    "    #df_filtered['health_ins'] = df_filtered['health_ins'].replace({True: 1, False: 0})\n",
    "    \n",
    "    handle_gas_feature(df_filtered)\n",
    "    \n",
    "    df_filtered['age_income'] = df_filtered.age * df_filtered.income\n",
    "    \n",
    "    df_missing = df[rows_with_missing | rows_with_age_120]\n",
    "    \n",
    "    return df_filtered, df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_27360\\4171155547.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_27360\\4171155547.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_27360\\4171155547.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_27360\\4171155547.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n"
     ]
    }
   ],
   "source": [
    "df_filtered, df_missing = apply_data_engineering(raw_data)\n",
    "sub_filtered, sub_missing = apply_data_engineering(masked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify_sample_then_split(train_df, smote_data, {'n_neighbors': [3]}, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col in categorical_features or col in label_features:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in numerical_features:\n",
    "            df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_df = pd.concat([df_filtered, df_missing], axis=0, ignore_index=True)\n",
    "\n",
    "xgb_train_df.drop(columns=['custid'], inplace=True)\n",
    "\n",
    "convert_feature_types(xgb_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9050050602631337\n"
     ]
    }
   ],
   "source": [
    "#### THIS CODE IS FOR THE XGBOOST MODEL ####\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is the column you want to predict\n",
    "X = xgb_train_df.drop(target_feature, axis=1)\n",
    "y = xgb_train_df[target_feature]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "predictions = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_threshold:  0.9325274\n"
     ]
    }
   ],
   "source": [
    "X_train = xgb_train_df.drop(columns=target_feature)\n",
    "y_train = xgb_train_df[target_feature]\n",
    "\n",
    "masked_df = pd.concat([sub_filtered, sub_missing], axis=0, ignore_index=True)\n",
    "\n",
    "X_submission = masked_df.drop(columns=['custid', 'health_ins'])\n",
    "\n",
    "convert_feature_types(X_submission)\n",
    "\n",
    "X_sub_matrix = xgb.DMatrix(X_submission, enable_categorical=True)\n",
    "\n",
    "y_pred = bst.predict(X_sub_matrix)\n",
    "\n",
    "# Compute the median of the predictions\n",
    "median_threshold = np.median(y_pred)\n",
    "\n",
    "print(\"median_threshold: \", median_threshold)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "submission_df = pd.DataFrame({\n",
    "    'custid': masked_df['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Convert the numeric values in 'predicted_y' to 'TRUE' or 'FALSE' based on the median threshold\n",
    "submission_df['health_ins'] = submission_df['health_ins'].apply(lambda x: 'TRUE' if x > median_threshold else 'FALSE')\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "submission_df.to_csv('xgb_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_df_filtered(sample_function, params, classifier):\n",
    "    # Preprocess data\n",
    "    train_df = df_filtered.drop('custid', axis=1)\n",
    "    test_df = sub_filtered.drop('custid', axis=1)\n",
    "    \n",
    "    preprocessed_train_df = preprocess_dataframe(train_df)\n",
    "    preprocessed_test_df = preprocess_dataframe(test_df)\n",
    "\n",
    "    X_train = preprocessed_train_df.drop(target_feature, axis=1)  \n",
    "    y_train = preprocessed_train_df[target_feature]\n",
    "    \n",
    "    # Sample data\n",
    "    X_resampled, y_resampled = sample_function(X_train, y_train)\n",
    "\n",
    "        \n",
    "    X_test = preprocessed_test_df.drop(target_feature, axis=1)  \n",
    "        \n",
    "    # Train model with GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=params, cv=5)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    # grid_search.fit(X_train, y)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'custid': sub_filtered['custid'],  \n",
    "        'health_ins': y_pred        \n",
    "    })\n",
    "        \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_df_missing():\n",
    "    \n",
    "    convert_feature_types(df_missing)\n",
    "    convert_feature_types(sub_missing)\n",
    "\n",
    "    train_df = df_missing.drop('custid', axis=1)\n",
    "    test_df = sub_missing.drop('custid', axis=1)\n",
    "    \n",
    "    X_train = train_df.drop(target_feature, axis=1)  \n",
    "    y_train = train_df[target_feature]\n",
    "    \n",
    "    X_test = test_df.drop(target_feature, axis=1)  \n",
    "        \n",
    "    dtrain = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
    "    dtest = xgb.DMatrix(X_test, enable_categorical=True)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # For binary classification\n",
    "        'max_depth': 6,\n",
    "        'eta': 0.3,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    num_rounds = 100\n",
    "    bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    preds = bst.predict(dtest)\n",
    "    predictions = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'custid': sub_missing['custid'],  \n",
    "        'health_ins': predictions        \n",
    "    })\n",
    "        \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submission_df_filtered \u001b[38;5;241m=\u001b[39m submission_df_filtered(smote_data, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m]}, KNeighborsClassifier())\n",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m, in \u001b[0;36msubmission_df_filtered\u001b[1;34m(sample_function, params, classifier)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train model with GridSearchCV\u001b[39;00m\n\u001b[0;32m     19\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclassifier, param_grid\u001b[38;5;241m=\u001b[39mparams, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# grid_search.fit(X_train, y)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:910\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    907\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    909\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 910\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[0;32m    911\u001b[0m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001b[0;32m    912\u001b[0m )\n\u001b[0;32m    913\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    969\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:455\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkneighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:849\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    842\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[0;32m    845\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[0;32m    846\u001b[0m     )\n\u001b[0;32m    847\u001b[0m )\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[1;32m--> 849\u001b[0m     results \u001b[38;5;241m=\u001b[39m ArgKmin\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    850\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    851\u001b[0m         Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X,\n\u001b[0;32m    852\u001b[0m         k\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[0;32m    853\u001b[0m         metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_,\n\u001b[0;32m    854\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_,\n\u001b[0;32m    855\u001b[0m         strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    856\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    857\u001b[0m     )\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[0;32m    861\u001b[0m ):\n\u001b[0;32m    862\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[0;32m    863\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[0;32m    864\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:278\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    279\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    280\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m    281\u001b[0m         k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    282\u001b[0m         metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m    283\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[0;32m    284\u001b[0m         metric_kwargs\u001b[38;5;241m=\u001b[39mmetric_kwargs,\n\u001b[0;32m    285\u001b[0m         strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m    286\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    291\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    292\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    298\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m    299\u001b[0m     )\n",
      "File \u001b[1;32msklearn\\\\metrics\\\\_pairwise_distances_reduction\\\\_argkmin.pyx:59\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\threadpoolctl.py:592\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[0;32m    595\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "submission_df_filtered = submission_df_filtered(smote_data, {'n_neighbors': [3]}, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_19980\\1789976068.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['sex', 'is_employed', 'income', 'marital_status', 'housing_type', 'num_vehicles', 'age', 'state_of_res', 'gas_usage', 'rooms', 'recent_move_b', 'gas_category', 'age_income'] ['sex', 'is_employed', 'income', 'marital_status', 'housing_type', 'num_vehicles', 'age', 'state_of_res', 'gas_usage', 'rooms', 'recent_move_b']\nexpected gas_category, age_income in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m submission_df_missing \u001b[38;5;241m=\u001b[39m submission_df_missing()\n",
      "Cell \u001b[1;32mIn[121], line 27\u001b[0m, in \u001b[0;36msubmission_df_missing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m num_rounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     25\u001b[0m bst \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(params, dtrain, num_rounds)\n\u001b[1;32m---> 27\u001b[0m preds \u001b[38;5;241m=\u001b[39m bst\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[0;32m     28\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m preds]\n\u001b[0;32m     30\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustid\u001b[39m\u001b[38;5;124m'\u001b[39m: sub_missing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustid\u001b[39m\u001b[38;5;124m'\u001b[39m],  \n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhealth_ins\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions        \n\u001b[0;32m     33\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\xgboost\\core.py:2359\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[0;32m   2357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m   2358\u001b[0m     fn \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfeature_names\n\u001b[1;32m-> 2359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(fn)\n\u001b[0;32m   2360\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   2361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: strict_shape,\n\u001b[0;32m   2366\u001b[0m }\n\u001b[0;32m   2368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massign_type\u001b[39m(t: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\xgboost\\core.py:3079\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3074\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3076\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3077\u001b[0m     )\n\u001b[1;32m-> 3079\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['sex', 'is_employed', 'income', 'marital_status', 'housing_type', 'num_vehicles', 'age', 'state_of_res', 'gas_usage', 'rooms', 'recent_move_b', 'gas_category', 'age_income'] ['sex', 'is_employed', 'income', 'marital_status', 'housing_type', 'num_vehicles', 'age', 'state_of_res', 'gas_usage', 'rooms', 'recent_move_b']\nexpected gas_category, age_income in input data"
     ]
    }
   ],
   "source": [
    "submission_df_missing = submission_df_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission_df = pd.concat([submission_df_filtered, submission_df_missing])\n",
    "\n",
    "submission_df['health_ins'] = submission_df['health_ins'].map({1.0: 'TRUE', 0.0: 'FALSE'})\n",
    "\n",
    "submission_df.to_csv('submission-try.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
