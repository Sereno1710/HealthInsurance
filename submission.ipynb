{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "raw_data = pd.read_csv('customer.csv')\n",
    "masked_df = pd.read_csv('customer_test_masked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = ['state_of_res']\n",
    "categorical_features = ['sex', 'marital_status', 'housing_type', 'gas_category', 'recent_move_b', 'is_employed']\n",
    "numerical_features = ['income', 'num_vehicles', 'age', 'gas_usage', 'rooms', 'age_income']\n",
    "target_feature = 'health_ins'\n",
    "id_feature = 'custid'\n",
    "\n",
    "# Define a preprocessor globally so it can be reused\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('label', OrdinalEncoder(), label_features),\n",
    "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('scaler', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "def preprocess_dataframe(df, fit_preprocessor=True):\n",
    "    global preprocessor  # Use the same preprocessor instance\n",
    "    \n",
    "    # Drop the target feature for feature processing\n",
    "    df_features = df.drop(target_feature, axis=1, errors='ignore')\n",
    "    \n",
    "    if fit_preprocessor:\n",
    "        # Fit and transform the preprocessor on training data\n",
    "        features_processed = preprocessor.fit_transform(df_features)\n",
    "    else:\n",
    "        # Only transform using an already fitted preprocessor\n",
    "        features_processed = preprocessor.transform(df_features)\n",
    "    \n",
    "    # Extract feature names from the preprocessor\n",
    "    feature_names = (\n",
    "        label_features +\n",
    "        preprocessor.named_transformers_['onehot'].get_feature_names_out(categorical_features).tolist() +\n",
    "        numerical_features +\n",
    "        [id_feature]\n",
    "    )\n",
    "    \n",
    "    # Create a DataFrame for the processed features\n",
    "    df_processed = pd.DataFrame(features_processed, columns=feature_names)\n",
    "    \n",
    "    # Ensure indices align\n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    \n",
    "    # Add the target feature back if it exists in the original DataFrame\n",
    "    if target_feature in df.columns:\n",
    "        df_target = df[target_feature].reset_index(drop=True)\n",
    "        df_processed[target_feature] = df_target\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample_then_split(df, sample_function, params, classifier):\n",
    "    # Preprocess data\n",
    "    preprocessed_df = preprocess_dataframe(df)\n",
    "\n",
    "    X = preprocessed_df.drop(target_feature, axis=1)  \n",
    "    y = preprocessed_df[target_feature]\n",
    "        \n",
    "    # Sample data\n",
    "    X_resampled, y_resampled = sample_function(X, y)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train model with GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=params, cv=5)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_gas_feature(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    gas_median = df_copy[df_copy['gas_usage'] > 3].gas_usage.median()\n",
    "\n",
    "    non_bill_cases_values = {\n",
    "        1: gas_median,\n",
    "        2: gas_median,\n",
    "        3: 0\n",
    "    }\n",
    "    non_bill_cases = {\n",
    "        1: 'Included in rent', \n",
    "        2: 'Included in electricity', \n",
    "        3: 'No charge'\n",
    "    }\n",
    "\n",
    "    # New feature for gas usage category\n",
    "    df_copy['gas_category'] = df_copy['gas_usage'].replace(non_bill_cases).where(\n",
    "        df_copy['gas_usage'].isin(non_bill_cases.keys()), 'Actual Bill'\n",
    "    )\n",
    "    df_copy.loc[pd.isna(df_copy['gas_usage']), 'gas_category'] = 'Unknown'\n",
    "\n",
    "    # Replace non-bill cases' values or maintain if not included\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].replace(non_bill_cases_values)\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].fillna(gas_median)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering(df):\n",
    "    \n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    df_filtered.drop(columns=['Unnamed: 0', 'code_column'], inplace=True)\n",
    "\n",
    "    rows_with_missing = df_filtered.isnull().sum(axis=1) > 2\n",
    "    df_filtered.drop(df_filtered[rows_with_missing].index, inplace=True)\n",
    "    \n",
    "    df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
    "    \n",
    "    df_filtered['num_vehicles'] = df_filtered['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].fillna(df_filtered['recent_move_b'].mode()[0])\n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_filtered['age'] = df_filtered['age'].replace(0, df_filtered['age'].median())\n",
    "    rows_with_age_120 = df_filtered['age'] == 120\n",
    "    df_filtered = df_filtered.drop(df_filtered[rows_with_age_120].index)\n",
    "    \n",
    "    df_filtered = handle_gas_feature(df_filtered)\n",
    "    \n",
    "    df_filtered['age_income'] = df_filtered.age * df_filtered.income\n",
    "    \n",
    "    df_missing = df[rows_with_missing | rows_with_age_120]\n",
    "    \n",
    "    return df_filtered, df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering_replace(df):\n",
    "    \n",
    "    df_replaced = df.copy()\n",
    "    \n",
    "    df_replaced.drop(columns=['Unnamed: 0', 'code_column'], inplace=True)\n",
    "\n",
    "    df_replaced['housing_type'] = df_replaced['housing_type'].fillna(df_replaced['housing_type'].mode()[0])\n",
    "    \n",
    "    df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
    "    \n",
    "    df_replaced['num_vehicles'] = df_replaced['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    df_replaced['recent_move_b'] = df_replaced['recent_move_b'].fillna(df_replaced['recent_move_b'].mode()[0])\n",
    "    df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_replaced['age'] = df_replaced['age'].replace(0, df_replaced['age'].median())\n",
    "    df_replaced['age'] = df_replaced['age'].replace(120, df_replaced['age'].median())\n",
    "    \n",
    "    df_replaced = handle_gas_feature(df_replaced)\n",
    "    \n",
    "    df_replaced['age_income'] = df_replaced.age * df_replaced.income\n",
    "    \n",
    "    return df_replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION\n",
    "\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\52935028.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\52935028.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\52935028.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\52935028.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n"
     ]
    }
   ],
   "source": [
    "df_filtered, df_missing = apply_data_engineering(raw_data)\n",
    "sub_filtered, sub_missing = apply_data_engineering(masked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col in categorical_features or col in label_features:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in numerical_features:\n",
    "            df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_df = pd.concat([df_filtered, df_missing], axis=0, ignore_index=True)\n",
    "\n",
    "xgb_train_df.drop(columns=['custid'], inplace=True)\n",
    "\n",
    "convert_feature_types(xgb_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9049130554788849\n"
     ]
    }
   ],
   "source": [
    "#### THIS CODE IS FOR THE XGBOOST MODEL ####\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is the column you want to predict\n",
    "X = xgb_train_df.drop(target_feature, axis=1)\n",
    "y = xgb_train_df[target_feature]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "predictions = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_threshold:  0.9317484\n"
     ]
    }
   ],
   "source": [
    "X_train = xgb_train_df.drop(columns=target_feature)\n",
    "y_train = xgb_train_df[target_feature]\n",
    "\n",
    "masked_df = pd.concat([sub_filtered, sub_missing], axis=0, ignore_index=True)\n",
    "\n",
    "X_submission = masked_df.drop(columns=['custid', 'health_ins'])\n",
    "\n",
    "convert_feature_types(X_submission)\n",
    "\n",
    "X_sub_matrix = xgb.DMatrix(X_submission, enable_categorical=True)\n",
    "\n",
    "y_pred = bst.predict(X_sub_matrix)\n",
    "\n",
    "# Compute the median of the predictions\n",
    "median_threshold = np.median(y_pred)\n",
    "\n",
    "print(\"median_threshold: \", median_threshold)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "xgb_submission_df = pd.DataFrame({\n",
    "    'custid': masked_df['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Convert the numeric values in 'predicted_y' to 'TRUE' or 'FALSE' based on the median threshold\n",
    "xgb_submission_df['health_ins'] = xgb_submission_df['health_ins'].apply(lambda x: 'TRUE' if x > median_threshold else 'FALSE')\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "xgb_submission_df.to_csv('xgb_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].fillna(df_replaced['recent_move_b'].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "rf_train_data = apply_data_engineering_replace(raw_data)\n",
    "rf_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "rf_train_data = preprocess_dataframe(rf_train_data, fit_preprocessor=True)\n",
    "rf_submission_data = preprocess_dataframe(rf_submission_data, fit_preprocessor=False)\n",
    "rf_submission_data['health_ins'] = rf_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote_data(X, y)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[0;32m     14\u001b[0m rf_submission_features \u001b[38;5;241m=\u001b[39m rf_submission_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_feature, id_feature])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m )(\n\u001b[0;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    495\u001b[0m         t,\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    497\u001b[0m         X,\n\u001b[0;32m    498\u001b[0m         y,\n\u001b[0;32m    499\u001b[0m         sample_weight,\n\u001b[0;32m    500\u001b[0m         i,\n\u001b[0;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    508\u001b[0m )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[0;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Athos\\anaconda3\\envs\\ICD\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# separate features\n",
    "X = rf_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = rf_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 20, 'n_estimators': 300}\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', criterion='gini', max_depth=20, n_estimators=300)\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "rf_submission_features = rf_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = rf_model.predict(rf_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "rf_submission_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_df.to_csv('rf_submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Probability: 0.179942974896693\n",
      "Index: 1, Probability: 0.18347297152126263\n",
      "Index: 2, Probability: 0.18779331243728373\n",
      "Index: 3, Probability: 0.19507628627867632\n",
      "Index: 4, Probability: 0.20110563218939334\n",
      "Index: 5, Probability: 0.20484834291055617\n",
      "Index: 6, Probability: 0.20662798069328406\n",
      "Index: 7, Probability: 0.21159171778309524\n",
      "Index: 8, Probability: 0.21360092828666888\n",
      "Index: 9, Probability: 0.22040735737443834\n",
      "Index: 10, Probability: 0.22728765731783857\n",
      "Index: 11, Probability: 0.22899419362441142\n",
      "Index: 12, Probability: 0.23593137573891784\n",
      "Index: 13, Probability: 0.23908921206422368\n",
      "Index: 14, Probability: 0.24275297553667646\n",
      "Index: 15, Probability: 0.2454912259278471\n",
      "Index: 16, Probability: 0.24867215370141524\n",
      "Index: 17, Probability: 0.25028649783576556\n",
      "Index: 18, Probability: 0.2511698591962649\n",
      "Index: 19, Probability: 0.257230820581578\n",
      "Index: 20, Probability: 0.2589906401967401\n",
      "Index: 21, Probability: 0.2601286606472161\n",
      "Index: 22, Probability: 0.2657550815605682\n",
      "Index: 23, Probability: 0.27098586473692365\n",
      "Index: 24, Probability: 0.2716233265403766\n",
      "Index: 25, Probability: 0.27358371657584535\n",
      "Index: 26, Probability: 0.2766927352003692\n",
      "Index: 27, Probability: 0.28226273690610537\n",
      "Index: 28, Probability: 0.2824964367307725\n",
      "Index: 29, Probability: 0.2905668284838603\n",
      "Index: 30, Probability: 0.29152452922758737\n",
      "Index: 31, Probability: 0.29818656325004667\n",
      "Index: 32, Probability: 0.31030036085351387\n",
      "Index: 33, Probability: 0.3134547650653735\n",
      "Index: 34, Probability: 0.3134771329886758\n",
      "Index: 35, Probability: 0.31368950833063364\n",
      "Index: 36, Probability: 0.31840962287825986\n",
      "Index: 37, Probability: 0.31961414927406406\n",
      "Index: 38, Probability: 0.3205465944855531\n",
      "Index: 39, Probability: 0.32116416461013053\n",
      "Index: 40, Probability: 0.3222379339946292\n",
      "Index: 41, Probability: 0.32671292954453973\n",
      "Index: 42, Probability: 0.3271002799820971\n",
      "Index: 43, Probability: 0.32756829164560175\n",
      "Index: 44, Probability: 0.327828410251807\n",
      "Index: 45, Probability: 0.3363842216149247\n",
      "Index: 46, Probability: 0.33952463830802193\n",
      "Index: 47, Probability: 0.3420353812500402\n",
      "Index: 48, Probability: 0.34769270973700167\n",
      "Index: 49, Probability: 0.35012366606401957\n",
      "Index: 50, Probability: 0.35090380701214907\n",
      "Index: 51, Probability: 0.3553665408547849\n",
      "Index: 52, Probability: 0.3578531897721033\n",
      "Index: 53, Probability: 0.35805075701242817\n",
      "Index: 54, Probability: 0.3595434525121147\n",
      "Index: 55, Probability: 0.3602394312199898\n",
      "Index: 56, Probability: 0.3625266929526531\n",
      "Index: 57, Probability: 0.3630624212218872\n",
      "Index: 58, Probability: 0.36559959958374433\n",
      "Index: 59, Probability: 0.3685208116859276\n",
      "Index: 60, Probability: 0.3708761106422514\n",
      "Index: 61, Probability: 0.3713374864495959\n",
      "Index: 62, Probability: 0.37368977305222995\n",
      "Index: 63, Probability: 0.37443354160753456\n",
      "Index: 64, Probability: 0.3785559245757467\n",
      "Index: 65, Probability: 0.3808876040049752\n",
      "Index: 66, Probability: 0.38102452589772773\n",
      "Index: 67, Probability: 0.3825045078761748\n",
      "Index: 68, Probability: 0.39159603013416905\n",
      "Index: 69, Probability: 0.3918782671449633\n",
      "Index: 70, Probability: 0.3920018221286595\n",
      "Index: 71, Probability: 0.3920842703250737\n",
      "Index: 72, Probability: 0.39227315824298936\n",
      "Index: 73, Probability: 0.39476656852065345\n",
      "Index: 74, Probability: 0.39834523605580924\n",
      "Index: 75, Probability: 0.4008384578970768\n",
      "Index: 76, Probability: 0.4015719072643932\n",
      "Index: 77, Probability: 0.40190561820946086\n",
      "Index: 78, Probability: 0.40214922567202394\n",
      "Index: 79, Probability: 0.40298048816833587\n",
      "Index: 80, Probability: 0.4071466599963785\n",
      "Index: 81, Probability: 0.408434502714284\n",
      "Index: 82, Probability: 0.4096080528025776\n",
      "Index: 83, Probability: 0.41072030903111756\n",
      "Index: 84, Probability: 0.4113718418232068\n",
      "Index: 85, Probability: 0.41298519176736054\n",
      "Index: 86, Probability: 0.4159633549991105\n",
      "Index: 87, Probability: 0.4160630870738819\n",
      "Index: 88, Probability: 0.41697195959413974\n",
      "Index: 89, Probability: 0.4174175267858462\n",
      "Index: 90, Probability: 0.4174835180443426\n",
      "Index: 91, Probability: 0.41889691632850634\n",
      "Index: 92, Probability: 0.41987096346473063\n",
      "Index: 93, Probability: 0.4200048760005186\n",
      "Index: 94, Probability: 0.4281098317490563\n",
      "Index: 95, Probability: 0.42820820873162185\n",
      "Index: 96, Probability: 0.4284363301778893\n",
      "Index: 97, Probability: 0.42928867683833405\n",
      "Index: 98, Probability: 0.43088844333312676\n",
      "Index: 99, Probability: 0.4316450583068384\n",
      "Index: 100, Probability: 0.43304569939891197\n",
      "Index: 101, Probability: 0.43604648982829114\n",
      "Index: 102, Probability: 0.4371532842923469\n",
      "Index: 103, Probability: 0.4399481368164992\n",
      "Index: 104, Probability: 0.4410447160821826\n",
      "Index: 105, Probability: 0.4416221034089842\n",
      "Index: 106, Probability: 0.4416463755958288\n",
      "Index: 107, Probability: 0.44171474214837825\n",
      "Index: 108, Probability: 0.4425725931392659\n",
      "Index: 109, Probability: 0.4468146290318807\n",
      "Index: 110, Probability: 0.446967510115921\n",
      "Index: 111, Probability: 0.44744326532657386\n",
      "Index: 112, Probability: 0.45234770183543066\n",
      "Index: 113, Probability: 0.45664674824196766\n",
      "Index: 114, Probability: 0.456701364569284\n",
      "Index: 115, Probability: 0.456929202522205\n",
      "Index: 116, Probability: 0.4572866969361844\n",
      "Index: 117, Probability: 0.4575045778034443\n",
      "Index: 118, Probability: 0.45912402682529335\n",
      "Index: 119, Probability: 0.4604992497031298\n",
      "Index: 120, Probability: 0.46111525589824914\n",
      "Index: 121, Probability: 0.46134436988764405\n",
      "Index: 122, Probability: 0.4652260099499466\n",
      "Index: 123, Probability: 0.46634732117309236\n",
      "Index: 124, Probability: 0.4665868930391546\n",
      "Index: 125, Probability: 0.46871174039772634\n",
      "Index: 126, Probability: 0.47010339554146224\n",
      "Index: 127, Probability: 0.4799722054788495\n",
      "Index: 128, Probability: 0.4814181307804185\n",
      "Index: 129, Probability: 0.48448314442833984\n",
      "Index: 130, Probability: 0.4897643211354773\n",
      "Index: 131, Probability: 0.49071472950935013\n",
      "Index: 132, Probability: 0.4926943939467252\n",
      "Index: 133, Probability: 0.4928513157675556\n",
      "Index: 134, Probability: 0.4965906232464987\n",
      "Index: 135, Probability: 0.497087489002361\n",
      "Index: 136, Probability: 0.4975684275524678\n",
      "Index: 137, Probability: 0.49796428795631265\n",
      "Index: 138, Probability: 0.5104920808653125\n",
      "Index: 139, Probability: 0.5105809414486986\n",
      "Index: 140, Probability: 0.5112162421876831\n",
      "Index: 141, Probability: 0.5113605322964208\n",
      "Index: 142, Probability: 0.5117941558252564\n",
      "Index: 143, Probability: 0.5134460422858543\n",
      "Index: 144, Probability: 0.514027765549371\n",
      "Index: 145, Probability: 0.5173193281066805\n",
      "Index: 146, Probability: 0.5182665359090568\n",
      "Index: 147, Probability: 0.5191798147885304\n",
      "Index: 148, Probability: 0.520164708066683\n",
      "Index: 149, Probability: 0.521304341541883\n",
      "Index: 150, Probability: 0.5234772295327524\n",
      "Index: 151, Probability: 0.5253322200027247\n",
      "Index: 152, Probability: 0.5261293377220567\n",
      "Index: 153, Probability: 0.5267005627361308\n",
      "Index: 154, Probability: 0.5280995496154036\n",
      "Index: 155, Probability: 0.5284047484124521\n",
      "Index: 156, Probability: 0.5315258075826436\n",
      "Index: 157, Probability: 0.5339969720793181\n",
      "Index: 158, Probability: 0.5362294187200167\n",
      "Index: 159, Probability: 0.5369263446467771\n",
      "Index: 160, Probability: 0.5400663221025436\n",
      "Index: 161, Probability: 0.5406952475593648\n",
      "Index: 162, Probability: 0.541464528143572\n",
      "Index: 163, Probability: 0.541600118897131\n",
      "Index: 164, Probability: 0.5422499690973297\n",
      "Index: 165, Probability: 0.542515279434358\n",
      "Index: 166, Probability: 0.543214038299266\n",
      "Index: 167, Probability: 0.5432213766961874\n",
      "Index: 168, Probability: 0.5463565002691388\n",
      "Index: 169, Probability: 0.5477850689781862\n",
      "Index: 170, Probability: 0.5500672306112308\n",
      "Index: 171, Probability: 0.5505855787605917\n",
      "Index: 172, Probability: 0.5532642749129462\n",
      "Index: 173, Probability: 0.5537932794578468\n",
      "Index: 174, Probability: 0.555205750945072\n",
      "Index: 175, Probability: 0.5552866473829055\n",
      "Index: 176, Probability: 0.5554121119721851\n",
      "Index: 177, Probability: 0.5560040315666605\n",
      "Index: 178, Probability: 0.5586772466408835\n",
      "Index: 179, Probability: 0.5596734979955341\n",
      "Index: 180, Probability: 0.5607151720790077\n",
      "Index: 181, Probability: 0.5630034191571133\n",
      "Index: 182, Probability: 0.5640856793778245\n",
      "Index: 183, Probability: 0.5654289969732728\n",
      "Index: 184, Probability: 0.5661378706350323\n",
      "Index: 185, Probability: 0.5672571863352138\n",
      "Index: 186, Probability: 0.5674600241906145\n",
      "Index: 187, Probability: 0.571044779832488\n",
      "Index: 188, Probability: 0.5710726073135598\n",
      "Index: 189, Probability: 0.5718288678347052\n",
      "Index: 190, Probability: 0.5722258136167867\n",
      "Index: 191, Probability: 0.5731189450787484\n",
      "Index: 192, Probability: 0.5738860947881792\n",
      "Index: 193, Probability: 0.574708946165704\n",
      "Index: 194, Probability: 0.575127325877082\n",
      "Index: 195, Probability: 0.5767794640784838\n",
      "Index: 196, Probability: 0.5773647689507619\n",
      "Index: 197, Probability: 0.577740308037344\n",
      "Index: 198, Probability: 0.5785336868044528\n",
      "Index: 199, Probability: 0.5788451032826207\n",
      "Index: 200, Probability: 0.5812341793549075\n",
      "Index: 201, Probability: 0.5825248467676147\n",
      "Index: 202, Probability: 0.5838450805627574\n",
      "Index: 203, Probability: 0.5841462757155427\n",
      "Index: 204, Probability: 0.5850007879874436\n",
      "Index: 205, Probability: 0.589334154634417\n",
      "Index: 206, Probability: 0.5893861295340701\n",
      "Index: 207, Probability: 0.5924402589765098\n",
      "Index: 208, Probability: 0.5952802422641236\n",
      "Index: 209, Probability: 0.5963055160105513\n",
      "Index: 210, Probability: 0.5967894324448147\n",
      "Index: 211, Probability: 0.5971933252791474\n",
      "Index: 212, Probability: 0.5981623748845719\n",
      "Index: 213, Probability: 0.6021461463309195\n",
      "Index: 214, Probability: 0.6021795725468042\n",
      "Index: 215, Probability: 0.6028568190381662\n",
      "Index: 216, Probability: 0.6029889864660192\n",
      "Index: 217, Probability: 0.6032834761131824\n",
      "Index: 218, Probability: 0.6037229403893731\n",
      "Index: 219, Probability: 0.6048747948541074\n",
      "Index: 220, Probability: 0.6067232488396951\n",
      "Index: 221, Probability: 0.6072128392015178\n",
      "Index: 222, Probability: 0.6083681889377608\n",
      "Index: 223, Probability: 0.6097174754220029\n",
      "Index: 224, Probability: 0.6100973925348634\n",
      "Index: 225, Probability: 0.6105165745339074\n",
      "Index: 226, Probability: 0.6105305626008433\n",
      "Index: 227, Probability: 0.6112813342165013\n",
      "Index: 228, Probability: 0.6118613151430695\n",
      "Index: 229, Probability: 0.6119731850140137\n",
      "Index: 230, Probability: 0.6121214570751952\n",
      "Index: 231, Probability: 0.6127566192347518\n",
      "Index: 232, Probability: 0.6135375511371826\n",
      "Index: 233, Probability: 0.6135382340505277\n",
      "Index: 234, Probability: 0.6138018504510294\n",
      "Index: 235, Probability: 0.6156402172302601\n",
      "Index: 236, Probability: 0.6159973957246144\n",
      "Index: 237, Probability: 0.6170260017541206\n",
      "Index: 238, Probability: 0.6173645236246993\n",
      "Index: 239, Probability: 0.6179342382639145\n",
      "Index: 240, Probability: 0.6195481061938282\n",
      "Index: 241, Probability: 0.6197060708960245\n",
      "Index: 242, Probability: 0.623229897922337\n",
      "Index: 243, Probability: 0.6243812883869541\n",
      "Index: 244, Probability: 0.6266960611195842\n",
      "Index: 245, Probability: 0.6278915169884602\n",
      "Index: 246, Probability: 0.6288316879560097\n",
      "Index: 247, Probability: 0.6304715961344787\n",
      "Index: 248, Probability: 0.6342878367798745\n",
      "Index: 249, Probability: 0.6354565311989243\n",
      "Index: 250, Probability: 0.6362189563885285\n",
      "Index: 251, Probability: 0.6362465284010651\n",
      "Index: 252, Probability: 0.6405568554264486\n",
      "Index: 253, Probability: 0.640628100603215\n",
      "Index: 254, Probability: 0.6424126840853835\n",
      "Index: 255, Probability: 0.642674871079633\n",
      "Index: 256, Probability: 0.6436452341131086\n",
      "Index: 257, Probability: 0.6438981069799699\n",
      "Index: 258, Probability: 0.6439450053279482\n",
      "Index: 259, Probability: 0.6448241659240231\n",
      "Index: 260, Probability: 0.6463472808833075\n",
      "Index: 261, Probability: 0.6468857965696252\n",
      "Index: 262, Probability: 0.6484332734929329\n",
      "Index: 263, Probability: 0.6491515594007786\n",
      "Index: 264, Probability: 0.6492891780108206\n",
      "Index: 265, Probability: 0.6498848166220558\n",
      "Index: 266, Probability: 0.6507627294247422\n",
      "Index: 267, Probability: 0.654721306239599\n",
      "Index: 268, Probability: 0.6556034855709499\n",
      "Index: 269, Probability: 0.6558897028931113\n",
      "Index: 270, Probability: 0.6568579677451422\n",
      "Index: 271, Probability: 0.6570195189332284\n",
      "Index: 272, Probability: 0.6581470336634264\n",
      "Index: 273, Probability: 0.6588890716221577\n",
      "Index: 274, Probability: 0.6593586784714196\n",
      "Index: 275, Probability: 0.6596215362420824\n",
      "Index: 276, Probability: 0.6612349930943284\n",
      "Index: 277, Probability: 0.6650115260529393\n",
      "Index: 278, Probability: 0.6658953297704363\n",
      "Index: 279, Probability: 0.6659981366275661\n",
      "Index: 280, Probability: 0.6670088202255469\n",
      "Index: 281, Probability: 0.6684545037894053\n",
      "Index: 282, Probability: 0.6693292747450584\n",
      "Index: 283, Probability: 0.6703836433867183\n",
      "Index: 284, Probability: 0.6711418399047236\n",
      "Index: 285, Probability: 0.6714205615378509\n",
      "Index: 286, Probability: 0.6723364754528246\n",
      "Index: 287, Probability: 0.6732486036713271\n",
      "Index: 288, Probability: 0.6740974721159254\n",
      "Index: 289, Probability: 0.6742073465168584\n",
      "Index: 290, Probability: 0.6749353098760655\n",
      "Index: 291, Probability: 0.6755745732648086\n",
      "Index: 292, Probability: 0.6757152313181118\n",
      "Index: 293, Probability: 0.6760240663786946\n",
      "Index: 294, Probability: 0.6760883851421878\n",
      "Index: 295, Probability: 0.6767353676322546\n",
      "Index: 296, Probability: 0.6807681850069475\n",
      "Index: 297, Probability: 0.6809714389388242\n",
      "Index: 298, Probability: 0.681777722487723\n",
      "Index: 299, Probability: 0.6819223452133395\n",
      "Index: 300, Probability: 0.6823114067123337\n",
      "Index: 301, Probability: 0.6829051593801235\n",
      "Index: 302, Probability: 0.683241646547624\n",
      "Index: 303, Probability: 0.6838359625050549\n",
      "Index: 304, Probability: 0.6875640632832889\n",
      "Index: 305, Probability: 0.6887144234390781\n",
      "Index: 306, Probability: 0.6890848642948928\n",
      "Index: 307, Probability: 0.690139816914246\n",
      "Index: 308, Probability: 0.6909248169578096\n",
      "Index: 309, Probability: 0.691109477687142\n",
      "Index: 310, Probability: 0.6914220905803233\n",
      "Index: 311, Probability: 0.6945941374388006\n",
      "Index: 312, Probability: 0.6951121987250569\n",
      "Index: 313, Probability: 0.69672994042588\n",
      "Index: 314, Probability: 0.6989797323303676\n",
      "Index: 315, Probability: 0.6997487274474665\n",
      "Index: 316, Probability: 0.7001444340546081\n",
      "Index: 317, Probability: 0.7002847189563702\n",
      "Index: 318, Probability: 0.7010179125759538\n",
      "Index: 319, Probability: 0.7016428383284288\n",
      "Index: 320, Probability: 0.7020976203699958\n",
      "Index: 321, Probability: 0.7023136589639701\n",
      "Index: 322, Probability: 0.7023463760311721\n",
      "Index: 323, Probability: 0.7024969271410254\n",
      "Index: 324, Probability: 0.7029726150204895\n",
      "Index: 325, Probability: 0.7029988319646602\n",
      "Index: 326, Probability: 0.7038958201545786\n",
      "Index: 327, Probability: 0.7042440260282561\n",
      "Index: 328, Probability: 0.7045154981962575\n",
      "Index: 329, Probability: 0.7045419766350085\n",
      "Index: 330, Probability: 0.7055605610178758\n",
      "Index: 331, Probability: 0.7055669242509631\n",
      "Index: 332, Probability: 0.7062351006804956\n",
      "Index: 333, Probability: 0.7062686624197659\n",
      "Index: 334, Probability: 0.7071213412699149\n",
      "Index: 335, Probability: 0.7072488584934683\n",
      "Index: 336, Probability: 0.7080639466408232\n",
      "Index: 337, Probability: 0.7081409499822965\n",
      "Index: 338, Probability: 0.7093962682827908\n",
      "Index: 339, Probability: 0.7106295391297455\n",
      "Index: 340, Probability: 0.7112964732993553\n",
      "Index: 341, Probability: 0.7121975206663697\n",
      "Index: 342, Probability: 0.7123932037283178\n",
      "Index: 343, Probability: 0.714049660462075\n",
      "Index: 344, Probability: 0.7146097732220325\n",
      "Index: 345, Probability: 0.7156094452610378\n",
      "Index: 346, Probability: 0.7164869419569698\n",
      "Index: 347, Probability: 0.7171743856608024\n",
      "Index: 348, Probability: 0.7173160968543327\n",
      "Index: 349, Probability: 0.7178028995441218\n",
      "Index: 350, Probability: 0.7182798303004201\n",
      "Index: 351, Probability: 0.7186396687666323\n",
      "Index: 352, Probability: 0.7195623690161325\n",
      "Index: 353, Probability: 0.7196510230822958\n",
      "Index: 354, Probability: 0.7202507766605055\n",
      "Index: 355, Probability: 0.7206702795854422\n",
      "Index: 356, Probability: 0.7220453907674137\n",
      "Index: 357, Probability: 0.7227354262259225\n",
      "Index: 358, Probability: 0.7279883943575115\n",
      "Index: 359, Probability: 0.7283632502789981\n",
      "Index: 360, Probability: 0.7284084317837145\n",
      "Index: 361, Probability: 0.7287235517994576\n",
      "Index: 362, Probability: 0.7288794053862697\n",
      "Index: 363, Probability: 0.7292574133853343\n",
      "Index: 364, Probability: 0.7304590921270222\n",
      "Index: 365, Probability: 0.7315699411001102\n",
      "Index: 366, Probability: 0.7315755271936724\n",
      "Index: 367, Probability: 0.733339532204326\n",
      "Index: 368, Probability: 0.7350965415996352\n",
      "Index: 369, Probability: 0.736288971408246\n",
      "Index: 370, Probability: 0.7367797483699188\n",
      "Index: 371, Probability: 0.7374110736204967\n",
      "Index: 372, Probability: 0.7377932332030035\n",
      "Index: 373, Probability: 0.7377976574191859\n",
      "Index: 374, Probability: 0.7381821547073977\n",
      "Index: 375, Probability: 0.7386280931126304\n",
      "Index: 376, Probability: 0.7421356608952645\n",
      "Index: 377, Probability: 0.743959226100803\n",
      "Index: 378, Probability: 0.7464485332700358\n",
      "Index: 379, Probability: 0.7487782459721691\n",
      "Index: 380, Probability: 0.7497090981747122\n",
      "Index: 381, Probability: 0.7497389227751992\n",
      "Index: 382, Probability: 0.7506981587763761\n",
      "Index: 383, Probability: 0.7511381700282538\n",
      "Index: 384, Probability: 0.7519252711865527\n",
      "Index: 385, Probability: 0.7523179555953174\n",
      "Index: 386, Probability: 0.7528044551097018\n",
      "Index: 387, Probability: 0.7539268188238619\n",
      "Index: 388, Probability: 0.7552376438219975\n",
      "Index: 389, Probability: 0.7556227601650158\n",
      "Index: 390, Probability: 0.755676498611009\n",
      "Index: 391, Probability: 0.7561529438021822\n",
      "Index: 392, Probability: 0.7561765891791374\n",
      "Index: 393, Probability: 0.7563824736351213\n",
      "Index: 394, Probability: 0.7569423351014384\n",
      "Index: 395, Probability: 0.7578457158372816\n",
      "Index: 396, Probability: 0.7601705988015106\n",
      "Index: 397, Probability: 0.7607256840217208\n",
      "Index: 398, Probability: 0.762345658386839\n",
      "Index: 399, Probability: 0.7628947530494701\n",
      "Index: 400, Probability: 0.7647381961968028\n",
      "Index: 401, Probability: 0.7648611111111111\n",
      "Index: 402, Probability: 0.7658434374183631\n",
      "Index: 403, Probability: 0.7659293297777969\n",
      "Index: 404, Probability: 0.7662087466846235\n",
      "Index: 405, Probability: 0.7663682768835413\n",
      "Index: 406, Probability: 0.7668400053185671\n",
      "Index: 407, Probability: 0.7678054561939188\n",
      "Index: 408, Probability: 0.7680110122096745\n",
      "Index: 409, Probability: 0.7685438950966212\n",
      "Index: 410, Probability: 0.769465785456399\n",
      "Index: 411, Probability: 0.769893873859868\n",
      "Index: 412, Probability: 0.7700090308842238\n",
      "Index: 413, Probability: 0.772515876210598\n",
      "Index: 414, Probability: 0.7749474909162204\n",
      "Index: 415, Probability: 0.7767496517597795\n",
      "Index: 416, Probability: 0.7783524241991793\n",
      "Index: 417, Probability: 0.7786896642586448\n",
      "Index: 418, Probability: 0.7797224147535086\n",
      "Index: 419, Probability: 0.7814275808849435\n",
      "Index: 420, Probability: 0.7814436599823823\n",
      "Index: 421, Probability: 0.7832704735148198\n",
      "Index: 422, Probability: 0.783474669380035\n",
      "Index: 423, Probability: 0.7839063121285709\n",
      "Index: 424, Probability: 0.7845464725390773\n",
      "Index: 425, Probability: 0.78518517064338\n",
      "Index: 426, Probability: 0.7855657421504313\n",
      "Index: 427, Probability: 0.7863325384296065\n",
      "Index: 428, Probability: 0.7873165823177041\n",
      "Index: 429, Probability: 0.787552429819499\n",
      "Index: 430, Probability: 0.788270795785392\n",
      "Index: 431, Probability: 0.7898474450147873\n",
      "Index: 432, Probability: 0.7916990505167014\n",
      "Index: 433, Probability: 0.7935589266425507\n",
      "Index: 434, Probability: 0.7940467582157172\n",
      "Index: 435, Probability: 0.7940900666833749\n",
      "Index: 436, Probability: 0.794290257034472\n",
      "Index: 437, Probability: 0.7949454667952144\n",
      "Index: 438, Probability: 0.7951351630447984\n",
      "Index: 439, Probability: 0.795764707953914\n",
      "Index: 440, Probability: 0.7962025828841353\n",
      "Index: 441, Probability: 0.7971510635728708\n",
      "Index: 442, Probability: 0.7977042314630283\n",
      "Index: 443, Probability: 0.798226748284686\n",
      "Index: 444, Probability: 0.7986231116581806\n",
      "Index: 445, Probability: 0.7998880583731014\n",
      "Index: 446, Probability: 0.8002190255686155\n",
      "Index: 447, Probability: 0.801413917851196\n",
      "Index: 448, Probability: 0.8031720492193053\n",
      "Index: 449, Probability: 0.8039811805742654\n",
      "Index: 450, Probability: 0.8051373215818687\n",
      "Index: 451, Probability: 0.8051945316240215\n",
      "Index: 452, Probability: 0.8056645669130038\n",
      "Index: 453, Probability: 0.8059831136217978\n",
      "Index: 454, Probability: 0.80697233535775\n",
      "Index: 455, Probability: 0.807074170646505\n",
      "Index: 456, Probability: 0.8078172272338278\n",
      "Index: 457, Probability: 0.8086827602950855\n",
      "Index: 458, Probability: 0.8091571955922564\n",
      "Index: 459, Probability: 0.8092798843142416\n",
      "Index: 460, Probability: 0.8113808215820787\n",
      "Index: 461, Probability: 0.8116675654550204\n",
      "Index: 462, Probability: 0.8124007735621745\n",
      "Index: 463, Probability: 0.8128685794359373\n",
      "Index: 464, Probability: 0.8136813055655868\n",
      "Index: 465, Probability: 0.8140029503905979\n",
      "Index: 466, Probability: 0.8141588957326819\n",
      "Index: 467, Probability: 0.8141869184276589\n",
      "Index: 468, Probability: 0.8142044521372593\n",
      "Index: 469, Probability: 0.8148388545233417\n",
      "Index: 470, Probability: 0.8152808782526627\n",
      "Index: 471, Probability: 0.8158145886660306\n",
      "Index: 472, Probability: 0.8162710999318424\n",
      "Index: 473, Probability: 0.816610920337397\n",
      "Index: 474, Probability: 0.8183004110500406\n",
      "Index: 475, Probability: 0.819168787158073\n",
      "Index: 476, Probability: 0.8203140455375493\n",
      "Index: 477, Probability: 0.8207371596247343\n",
      "Index: 478, Probability: 0.822975625834745\n",
      "Index: 479, Probability: 0.8232063945744826\n",
      "Index: 480, Probability: 0.8234060796565071\n",
      "Index: 481, Probability: 0.8234295594992058\n",
      "Index: 482, Probability: 0.8243798257269529\n",
      "Index: 483, Probability: 0.8244610069456453\n",
      "Index: 484, Probability: 0.8247044494984374\n",
      "Index: 485, Probability: 0.8249592732371201\n",
      "Index: 486, Probability: 0.8252986710046707\n",
      "Index: 487, Probability: 0.827754364789769\n",
      "Index: 488, Probability: 0.8284455793286416\n",
      "Index: 489, Probability: 0.8288249939221501\n",
      "Index: 490, Probability: 0.8291036561068605\n",
      "Index: 491, Probability: 0.830953121694142\n",
      "Index: 492, Probability: 0.831685923227535\n",
      "Index: 493, Probability: 0.8318357580203368\n",
      "Index: 494, Probability: 0.83277365526768\n",
      "Index: 495, Probability: 0.8329738409690128\n",
      "Index: 496, Probability: 0.8335627987906762\n",
      "Index: 497, Probability: 0.8353958847472032\n",
      "Index: 498, Probability: 0.8354705070102385\n",
      "Index: 499, Probability: 0.8363628499769782\n",
      "Index: 500, Probability: 0.8367283290142357\n",
      "Index: 501, Probability: 0.8389096452237808\n",
      "Index: 502, Probability: 0.8397096250827595\n",
      "Index: 503, Probability: 0.8399377399128428\n",
      "Index: 504, Probability: 0.8400485799657954\n",
      "Index: 505, Probability: 0.8405358502581088\n",
      "Index: 506, Probability: 0.841834289621318\n",
      "Index: 507, Probability: 0.8420675172071738\n",
      "Index: 508, Probability: 0.8421916295905277\n",
      "Index: 509, Probability: 0.8426546770290344\n",
      "Index: 510, Probability: 0.8436847979364429\n",
      "Index: 511, Probability: 0.8482333796883527\n",
      "Index: 512, Probability: 0.8491179346025808\n",
      "Index: 513, Probability: 0.8500494617860292\n",
      "Index: 514, Probability: 0.8516618298057705\n",
      "Index: 515, Probability: 0.8518497746154483\n",
      "Index: 516, Probability: 0.8538845267712651\n",
      "Index: 517, Probability: 0.8580739686682868\n",
      "Index: 518, Probability: 0.8580837838842954\n",
      "Index: 519, Probability: 0.8585685459026168\n",
      "Index: 520, Probability: 0.8586645658996906\n",
      "Index: 521, Probability: 0.8588316478193034\n",
      "Index: 522, Probability: 0.8589700047729323\n",
      "Index: 523, Probability: 0.8603341953934656\n",
      "Index: 524, Probability: 0.8607793075477204\n",
      "Index: 525, Probability: 0.8612283254612555\n",
      "Index: 526, Probability: 0.862807219395101\n",
      "Index: 527, Probability: 0.8634884340399196\n",
      "Index: 528, Probability: 0.8637547281949174\n",
      "Index: 529, Probability: 0.8653474385494871\n",
      "Index: 530, Probability: 0.8660167889483432\n",
      "Index: 531, Probability: 0.8660518744416816\n",
      "Index: 532, Probability: 0.8668821876042104\n",
      "Index: 533, Probability: 0.8669072963810739\n",
      "Index: 534, Probability: 0.8670217968646693\n",
      "Index: 535, Probability: 0.8672749121515944\n",
      "Index: 536, Probability: 0.8689611357976692\n",
      "Index: 537, Probability: 0.8690265151935065\n",
      "Index: 538, Probability: 0.8699787226911515\n",
      "Index: 539, Probability: 0.869988644504841\n",
      "Index: 540, Probability: 0.8704666432148631\n",
      "Index: 541, Probability: 0.8706882209375597\n",
      "Index: 542, Probability: 0.871163817266462\n",
      "Index: 543, Probability: 0.8718132265513535\n",
      "Index: 544, Probability: 0.8718806045395563\n",
      "Index: 545, Probability: 0.8727364661310361\n",
      "Index: 546, Probability: 0.8740224548883481\n",
      "Index: 547, Probability: 0.8744603711699497\n",
      "Index: 548, Probability: 0.8750663394401919\n",
      "Index: 549, Probability: 0.876778347541788\n",
      "Index: 550, Probability: 0.8771610764230601\n",
      "Index: 551, Probability: 0.8775961698780967\n",
      "Index: 552, Probability: 0.879304811161741\n",
      "Index: 553, Probability: 0.880239605646791\n",
      "Index: 554, Probability: 0.8818730642898358\n",
      "Index: 555, Probability: 0.8820513164674153\n",
      "Index: 556, Probability: 0.883456202265718\n",
      "Index: 557, Probability: 0.8855210745997476\n",
      "Index: 558, Probability: 0.8858034427410163\n",
      "Index: 559, Probability: 0.889448163542154\n",
      "Index: 560, Probability: 0.8902996218478122\n",
      "Index: 561, Probability: 0.8916816769686382\n",
      "Index: 562, Probability: 0.8916899604588527\n",
      "Index: 563, Probability: 0.891866977947201\n",
      "Index: 564, Probability: 0.891983359140332\n",
      "Index: 565, Probability: 0.8929297464896333\n",
      "Index: 566, Probability: 0.8932425060374047\n",
      "Index: 567, Probability: 0.8963415145456503\n",
      "Index: 568, Probability: 0.8965395235869342\n",
      "Index: 569, Probability: 0.8974527868188883\n",
      "Index: 570, Probability: 0.8988153718296138\n",
      "Index: 571, Probability: 0.8991186279981918\n",
      "Index: 572, Probability: 0.9001730581090143\n",
      "Index: 573, Probability: 0.900981347947625\n",
      "Index: 574, Probability: 0.9024369653612017\n",
      "Index: 575, Probability: 0.9025464410045775\n",
      "Index: 576, Probability: 0.903045807995631\n",
      "Index: 577, Probability: 0.9031540880636036\n",
      "Index: 578, Probability: 0.9072882579082022\n",
      "Index: 579, Probability: 0.9101844933753452\n",
      "Index: 580, Probability: 0.9104138578946871\n",
      "Index: 581, Probability: 0.9121554877566079\n",
      "Index: 582, Probability: 0.9130409174550791\n",
      "Index: 583, Probability: 0.9130608873844972\n",
      "Index: 584, Probability: 0.9136293260473587\n",
      "Index: 585, Probability: 0.9167331351785099\n",
      "Index: 586, Probability: 0.9175932073408798\n",
      "Index: 587, Probability: 0.918201872658864\n",
      "Index: 588, Probability: 0.918290537845152\n",
      "Index: 589, Probability: 0.9192057337518715\n",
      "Index: 590, Probability: 0.9206058827713757\n",
      "Index: 591, Probability: 0.9211091066441979\n",
      "Index: 592, Probability: 0.9222838565110675\n",
      "Index: 593, Probability: 0.9230212521935566\n",
      "Index: 594, Probability: 0.9243383970973295\n",
      "Index: 595, Probability: 0.9250225852835744\n",
      "Index: 596, Probability: 0.9256315845730116\n",
      "Index: 597, Probability: 0.9257076904186675\n",
      "Index: 598, Probability: 0.9273594848828735\n",
      "Index: 599, Probability: 0.9274290403102841\n",
      "Index: 600, Probability: 0.9295537884120787\n",
      "Index: 601, Probability: 0.9313022127569648\n",
      "Index: 602, Probability: 0.9325219515293086\n",
      "Index: 603, Probability: 0.9326293426603987\n",
      "Index: 604, Probability: 0.934236695901554\n",
      "Index: 605, Probability: 0.9363913029503008\n",
      "Index: 606, Probability: 0.9384660387692105\n",
      "Index: 607, Probability: 0.9389397041319361\n",
      "Index: 608, Probability: 0.9391585477102717\n",
      "Index: 609, Probability: 0.9395948806983326\n",
      "Index: 610, Probability: 0.9400158609390615\n",
      "Index: 611, Probability: 0.9401138233570169\n",
      "Index: 612, Probability: 0.9406079962104108\n",
      "Index: 613, Probability: 0.9417668175037653\n",
      "Index: 614, Probability: 0.9420304225931265\n",
      "Index: 615, Probability: 0.9437710541467746\n",
      "Index: 616, Probability: 0.9452034788311052\n",
      "Index: 617, Probability: 0.9454397933144572\n",
      "Index: 618, Probability: 0.9457302125098601\n",
      "Index: 619, Probability: 0.9468270796945427\n",
      "Index: 620, Probability: 0.94779223839099\n",
      "Index: 621, Probability: 0.9489479153348763\n",
      "Index: 622, Probability: 0.9490815687155894\n",
      "Index: 623, Probability: 0.9496260969197828\n",
      "Index: 624, Probability: 0.94962694800151\n",
      "Index: 625, Probability: 0.9498291324342018\n",
      "Index: 626, Probability: 0.9500641527716097\n",
      "Index: 627, Probability: 0.95047450341375\n",
      "Index: 628, Probability: 0.9519462985182713\n",
      "Index: 629, Probability: 0.952534365761342\n",
      "Index: 630, Probability: 0.9529137244520917\n",
      "Index: 631, Probability: 0.9545970191141993\n",
      "Index: 632, Probability: 0.9549177908793944\n",
      "Index: 633, Probability: 0.9552424826020469\n",
      "Index: 634, Probability: 0.955268813316642\n",
      "Index: 635, Probability: 0.9555959926119985\n",
      "Index: 636, Probability: 0.9558319481482793\n",
      "Index: 637, Probability: 0.9559102110429321\n",
      "Index: 638, Probability: 0.9564088686376251\n",
      "Index: 639, Probability: 0.9566901946465048\n",
      "Index: 640, Probability: 0.9566962711959768\n",
      "Index: 641, Probability: 0.9570085889221616\n",
      "Index: 642, Probability: 0.9584026668153678\n",
      "Index: 643, Probability: 0.958740522875817\n",
      "Index: 644, Probability: 0.9590125974381944\n",
      "Index: 645, Probability: 0.959334264569148\n",
      "Index: 646, Probability: 0.959941653647387\n",
      "Index: 647, Probability: 0.9601249514062825\n",
      "Index: 648, Probability: 0.9604241784995865\n",
      "Index: 649, Probability: 0.9604695906432748\n",
      "Index: 650, Probability: 0.9612340653383097\n",
      "Index: 651, Probability: 0.9617935642233221\n",
      "Index: 652, Probability: 0.961834908619694\n",
      "Index: 653, Probability: 0.9622435897435897\n",
      "Index: 654, Probability: 0.9630049924532682\n",
      "Index: 655, Probability: 0.9632105654071701\n",
      "Index: 656, Probability: 0.9634421788263844\n",
      "Index: 657, Probability: 0.963637439359616\n",
      "Index: 658, Probability: 0.9646142603882402\n",
      "Index: 659, Probability: 0.9647404107606835\n",
      "Index: 660, Probability: 0.964797069738086\n",
      "Index: 661, Probability: 0.9654136810584864\n",
      "Index: 662, Probability: 0.9654498211639373\n",
      "Index: 663, Probability: 0.9654607249266538\n",
      "Index: 664, Probability: 0.9658940482944254\n",
      "Index: 665, Probability: 0.9660587394152007\n",
      "Index: 666, Probability: 0.9663268894478885\n",
      "Index: 667, Probability: 0.9664300961448435\n",
      "Index: 668, Probability: 0.9667212963180151\n",
      "Index: 669, Probability: 0.9670283583089356\n",
      "Index: 670, Probability: 0.9670653849640621\n",
      "Index: 671, Probability: 0.9672314124218504\n",
      "Index: 672, Probability: 0.9677442416425315\n",
      "Index: 673, Probability: 0.9677642538368489\n",
      "Index: 674, Probability: 0.9681996216899055\n",
      "Index: 675, Probability: 0.9682990433181586\n",
      "Index: 676, Probability: 0.9689794142435706\n",
      "Index: 677, Probability: 0.9697793815440083\n",
      "Index: 678, Probability: 0.9716969927529828\n",
      "Index: 679, Probability: 0.9719214604118992\n",
      "Index: 680, Probability: 0.9719244295986152\n",
      "Index: 681, Probability: 0.9719840505575409\n",
      "Index: 682, Probability: 0.9725542555627907\n",
      "Index: 683, Probability: 0.9733333333333334\n",
      "Index: 684, Probability: 0.9750029338927855\n",
      "Index: 685, Probability: 0.9753468259067439\n",
      "Index: 686, Probability: 0.9756167432318296\n",
      "Index: 687, Probability: 0.9757702253433721\n",
      "Index: 688, Probability: 0.9758562592082315\n",
      "Index: 689, Probability: 0.9764734403210049\n",
      "Index: 690, Probability: 0.9770260170470434\n",
      "Index: 691, Probability: 0.9779609556219331\n",
      "Index: 692, Probability: 0.9780815327310745\n",
      "Index: 693, Probability: 0.9783333333333334\n",
      "Index: 694, Probability: 0.9784724197451928\n",
      "Index: 695, Probability: 0.9791256822640717\n",
      "Index: 696, Probability: 0.9792428080103199\n",
      "Index: 697, Probability: 0.9792849217882472\n",
      "Index: 698, Probability: 0.9796407605524554\n",
      "Index: 699, Probability: 0.9798729799408916\n",
      "Index: 700, Probability: 0.9799868247694333\n",
      "Index: 701, Probability: 0.98\n",
      "Index: 702, Probability: 0.9800597258623956\n",
      "Index: 703, Probability: 0.9807135076252723\n",
      "Index: 704, Probability: 0.9811809541828544\n",
      "Index: 705, Probability: 0.9812816773418291\n",
      "Index: 706, Probability: 0.9814075660010606\n",
      "Index: 707, Probability: 0.9816603605763595\n",
      "Index: 708, Probability: 0.9816885754454031\n",
      "Index: 709, Probability: 0.9820997165317334\n",
      "Index: 710, Probability: 0.9821207563801782\n",
      "Index: 711, Probability: 0.9821776526141546\n",
      "Index: 712, Probability: 0.9824067731035306\n",
      "Index: 713, Probability: 0.9827238654514584\n",
      "Index: 714, Probability: 0.9830179543604618\n",
      "Index: 715, Probability: 0.9830901522888819\n",
      "Index: 716, Probability: 0.9830940269849213\n",
      "Index: 717, Probability: 0.9831689126197136\n",
      "Index: 718, Probability: 0.9832456140350877\n",
      "Index: 719, Probability: 0.9833066666666666\n",
      "Index: 720, Probability: 0.9833333333333333\n",
      "Index: 721, Probability: 0.9834691054350486\n",
      "Index: 722, Probability: 0.9853084270867193\n",
      "Index: 723, Probability: 0.9854637057010986\n",
      "Index: 724, Probability: 0.9866666666666667\n",
      "Index: 725, Probability: 0.9867105023468359\n",
      "Index: 726, Probability: 0.9867822169132728\n",
      "Index: 727, Probability: 0.9874480946586288\n",
      "Index: 728, Probability: 0.9876943256090314\n",
      "Index: 729, Probability: 0.9877427294836978\n",
      "Index: 730, Probability: 0.9878605642230519\n",
      "Index: 731, Probability: 0.9880615534527889\n",
      "Index: 732, Probability: 0.988103012197292\n",
      "Index: 733, Probability: 0.988208791585785\n",
      "Index: 734, Probability: 0.9883399162507097\n",
      "Index: 735, Probability: 0.9899775533108867\n",
      "Index: 736, Probability: 0.9899844961240309\n",
      "Index: 737, Probability: 0.99\n",
      "Index: 738, Probability: 0.99\n",
      "Index: 739, Probability: 0.9903864249619668\n",
      "Index: 740, Probability: 0.9908575375971854\n",
      "Index: 741, Probability: 0.9915248365607819\n",
      "Index: 742, Probability: 0.9915443072114736\n",
      "Index: 743, Probability: 0.9916800126733222\n",
      "Index: 744, Probability: 0.9917830690809891\n",
      "Index: 745, Probability: 0.9920487358960322\n",
      "Index: 746, Probability: 0.9920642809755184\n",
      "Index: 747, Probability: 0.9928358162813763\n",
      "Index: 748, Probability: 0.9928736424140249\n",
      "Index: 749, Probability: 0.9928934004729515\n",
      "Index: 750, Probability: 0.9930811346789328\n",
      "Index: 751, Probability: 0.9932068173496814\n",
      "Index: 752, Probability: 0.9933333333333333\n",
      "Index: 753, Probability: 0.9950419536297573\n",
      "Index: 754, Probability: 0.9951015916669581\n",
      "Index: 755, Probability: 0.9951419227533843\n",
      "Index: 756, Probability: 0.9952380952380951\n",
      "Index: 757, Probability: 0.9952962962962961\n",
      "Index: 758, Probability: 0.995747524351986\n",
      "Index: 759, Probability: 0.9958610781379146\n",
      "Index: 760, Probability: 0.9960743357384861\n",
      "Index: 761, Probability: 0.9961342023842025\n",
      "Index: 762, Probability: 0.9961904761904761\n",
      "Index: 763, Probability: 0.9961904761904763\n",
      "Index: 764, Probability: 0.9966050016064006\n",
      "Index: 765, Probability: 0.9966228070175437\n",
      "Index: 766, Probability: 0.996641977105784\n",
      "Index: 767, Probability: 0.9966463877757945\n",
      "Index: 768, Probability: 0.9966574330563249\n",
      "Index: 769, Probability: 0.9966666666666667\n",
      "Index: 770, Probability: 0.9966666666666667\n",
      "Index: 771, Probability: 0.996847242378328\n",
      "Index: 772, Probability: 0.9971138072453861\n",
      "Index: 773, Probability: 0.9986365145139723\n",
      "Index: 774, Probability: 0.9989918842883672\n",
      "Index: 775, Probability: 0.9989974594861256\n",
      "Index: 776, Probability: 0.9991131324575611\n",
      "Index: 777, Probability: 0.9991275782183554\n",
      "Index: 778, Probability: 0.999128200709842\n",
      "Index: 779, Probability: 0.9991728799793884\n",
      "Index: 780, Probability: 0.9994543547073474\n",
      "Index: 781, Probability: 0.9994667123957246\n",
      "Index: 782, Probability: 0.9995883185289919\n",
      "Index: 783, Probability: 0.9996401835053697\n",
      "Index: 784, Probability: 0.9996574330563248\n",
      "Index: 785, Probability: 0.9997075798383993\n",
      "Index: 786, Probability: 0.9998039215686274\n",
      "Index: 787, Probability: 0.9998044624452395\n",
      "Index: 788, Probability: 0.9998454409787744\n",
      "Index: 789, Probability: 0.9999346405228758\n",
      "Index: 790, Probability: 0.9999346405228758\n",
      "Index: 791, Probability: 0.9999405162738496\n",
      "Index: 792, Probability: 0.9999708879184861\n",
      "Index: 793, Probability: 0.999984544049459\n",
      "Index: 794, Probability: 1.0\n",
      "Index: 795, Probability: 1.0\n",
      "Index: 796, Probability: 1.0\n",
      "Index: 797, Probability: 1.0\n",
      "Index: 798, Probability: 1.0\n",
      "Index: 799, Probability: 1.0\n",
      "Index: 800, Probability: 1.0\n",
      "Index: 801, Probability: 1.0\n",
      "Index: 802, Probability: 1.0\n",
      "Index: 803, Probability: 1.0\n"
     ]
    }
   ],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = rf_model.predict_proba(rf_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "#print the propability on the split point\n",
    "for i, prob in enumerate(sorted_indices):\n",
    "    print(f\"Index: {i}, Probability: {y_proba[prob]}\")\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "rf_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_balanced_df.to_csv('rf_submission_balanced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n"
     ]
    }
   ],
   "source": [
    "dt_train_data = apply_data_engineering_replace(raw_data)\n",
    "dt_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "dt_train_data = preprocess_dataframe(dt_train_data, fit_preprocessor=True)\n",
    "dt_submission_data = preprocess_dataframe(dt_submission_data, fit_preprocessor=False)\n",
    "dt_submission_data['health_ins'] = dt_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features\n",
    "X = dt_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = dt_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 29, 'splitter': 'best'}\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', criterion='entropy', max_depth=28, splitter='best')\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "dt_submission_features = dt_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = dt_model.predict(dt_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "dt_submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_df.to_csv('dt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "\n",
    "# Separate features and target\n",
    "X = dt_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = dt_train_data[target_feature]\n",
    "\n",
    "# Define model\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=29, splitter='best')\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Custom scoring function (optional, e.g., use accuracy)\n",
    "scoring = make_scorer(accuracy_score)\n",
    "\n",
    "# Resampling within cross-validation\n",
    "scores = []\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Resample training data\n",
    "    X_resampled, y_resampled = smote_data(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(scores):.4f}\")\n",
    "\n",
    "# Final model fit (using all data)\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict for submission data\n",
    "dt_submission_features = dt_submission_data.drop(columns=[target_feature, id_feature])\n",
    "y_pred = dt_model.predict(dt_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "dt_submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_df.to_csv('dt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = dt_model.predict_proba(dt_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "#print the propability on the split point\n",
    "#for i, prob in enumerate(sorted_indices):\n",
    "#    print(f\"Index: {i}, Probability: {y_proba[prob]}\")\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "dt_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_balanced_df.to_csv('dt_submission_balanced_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (=1 -> true, >1 -> false)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = dt_model.predict_proba(dt_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Initialize predictions based on the condition\n",
    "y_pred = (y_proba == 1).astype(bool)  # TRUE if probability is 1, FALSE otherwise\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "dt_submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred                      # Predictions based on the condition\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_df.to_csv('dt_submission_acc_true.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comparisons: 804\n",
      "Matches: 690 (85.82%)\n",
      "Mismatches: 114 (14.18%)\n"
     ]
    }
   ],
   "source": [
    "# Load the two CSV files\n",
    "df1 = pd.read_csv('dt_submission_balanced.csv')\n",
    "df2 = pd.read_csv('dt_submission_balanced_v2.csv')\n",
    "\n",
    "# Merge the DataFrames on the 'custid' column\n",
    "merged_df = pd.merge(df1, df2, on='custid', suffixes=('_v1', '_v2'))\n",
    "\n",
    "# Compare the health_ins values\n",
    "merged_df['match'] = merged_df['health_ins_v1'] == merged_df['health_ins_v2']\n",
    "\n",
    "# Calculate percentages\n",
    "total = len(merged_df)\n",
    "matches = merged_df['match'].sum()\n",
    "mismatches = total - matches\n",
    "\n",
    "percentage_match = (matches / total) * 100\n",
    "percentage_mismatch = (mismatches / total) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Total comparisons: {total}\")\n",
    "print(f\"Matches: {matches} ({percentage_match:.2f}%)\")\n",
    "print(f\"Mismatches: {mismatches} ({percentage_mismatch:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_data(X, y):\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22088\\3637797522.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].fillna(df_replaced['recent_move_b'].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "svm_train_data = apply_data_engineering_replace(raw_data)\n",
    "svm_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "svm_train_data = preprocess_dataframe(svm_train_data, fit_preprocessor=True)\n",
    "svm_submission_data = preprocess_dataframe(svm_submission_data, fit_preprocessor=False)\n",
    "svm_submission_data['health_ins'] = svm_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# separate features\n",
    "X = svm_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = svm_train_data[target_feature]\n",
    "\n",
    "# define model \n",
    "svm_model = SVC(C=0.1, kernel='rbf', gamma=0.01, class_weight='balanced')\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = undersample_data(X, y)\n",
    "\n",
    "# fit model\n",
    "svm_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "svm_submission_features = svm_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = svm_model.predict(svm_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "svm_submission_df = pd.DataFrame({\n",
    "    'custid': svm_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "svm_submission_df.to_csv('svm_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
