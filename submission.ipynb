{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "raw_data = pd.read_csv('customer.csv')\n",
    "masked_df = pd.read_csv('customer_test_masked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = ['state_of_res']\n",
    "categorical_features = ['sex', 'marital_status', 'housing_type', 'gas_category', 'recent_move_b', 'is_employed']\n",
    "numerical_features = ['income', 'num_vehicles', 'age', 'gas_usage', 'rooms', 'age_income']\n",
    "target_feature = 'health_ins'\n",
    "id_feature = 'custid'\n",
    "\n",
    "# Define a preprocessor globally so it can be reused\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('label', OrdinalEncoder(), label_features),\n",
    "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('scaler', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "def preprocess_dataframe(df, fit_preprocessor=True):\n",
    "    global preprocessor  # Use the same preprocessor instance\n",
    "    \n",
    "    # Drop the target feature for feature processing\n",
    "    df_features = df.drop(target_feature, axis=1, errors='ignore')\n",
    "    \n",
    "    if fit_preprocessor:\n",
    "        # Fit and transform the preprocessor on training data\n",
    "        features_processed = preprocessor.fit_transform(df_features)\n",
    "    else:\n",
    "        # Only transform using an already fitted preprocessor\n",
    "        features_processed = preprocessor.transform(df_features)\n",
    "    \n",
    "    # Extract feature names from the preprocessor\n",
    "    feature_names = (\n",
    "        label_features +\n",
    "        preprocessor.named_transformers_['onehot'].get_feature_names_out(categorical_features).tolist() +\n",
    "        numerical_features +\n",
    "        [id_feature]\n",
    "    )\n",
    "    \n",
    "    # Create a DataFrame for the processed features\n",
    "    df_processed = pd.DataFrame(features_processed, columns=feature_names)\n",
    "    \n",
    "    # Ensure indices align\n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    \n",
    "    # Add the target feature back if it exists in the original DataFrame\n",
    "    if target_feature in df.columns:\n",
    "        df_target = df[target_feature].reset_index(drop=True)\n",
    "        df_processed[target_feature] = df_target\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(X, y):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample_then_split(df, sample_function, params, classifier):\n",
    "    # Preprocess data\n",
    "    preprocessed_df = preprocess_dataframe(df)\n",
    "\n",
    "    X = preprocessed_df.drop(target_feature, axis=1)  \n",
    "    y = preprocessed_df[target_feature]\n",
    "        \n",
    "    # Sample data\n",
    "    X_resampled, y_resampled = sample_function(X, y)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train model with GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=params, cv=5)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_gas_feature(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    gas_median = df_copy[df_copy['gas_usage'] > 3].gas_usage.median()\n",
    "\n",
    "    non_bill_cases_values = {\n",
    "        1: gas_median,\n",
    "        2: gas_median,\n",
    "        3: 0\n",
    "    }\n",
    "    non_bill_cases = {\n",
    "        1: 'Included in rent', \n",
    "        2: 'Included in electricity', \n",
    "        3: 'No charge'\n",
    "    }\n",
    "\n",
    "    # New feature for gas usage category\n",
    "    df_copy['gas_category'] = df_copy['gas_usage'].replace(non_bill_cases).where(\n",
    "        df_copy['gas_usage'].isin(non_bill_cases.keys()), 'Actual Bill'\n",
    "    )\n",
    "    df_copy.loc[pd.isna(df_copy['gas_usage']), 'gas_category'] = 'Unknown'\n",
    "\n",
    "    # Replace non-bill cases' values or maintain if not included\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].replace(non_bill_cases_values)\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].fillna(gas_median)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering(df):\n",
    "    \n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    df_filtered.drop(columns=['Unnamed: 0', 'code_column'], inplace=True)\n",
    "\n",
    "    rows_with_missing = df_filtered.isnull().sum(axis=1) > 2\n",
    "    df_filtered.drop(df_filtered[rows_with_missing].index, inplace=True)\n",
    "    \n",
    "    df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
    "    \n",
    "    df_filtered['num_vehicles'] = df_filtered['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].fillna(df_filtered['recent_move_b'].mode()[0])\n",
    "    df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_filtered['age'] = df_filtered['age'].replace(0, df_filtered['age'].median())\n",
    "    rows_with_age_120 = df_filtered['age'] == 120\n",
    "    df_filtered = df_filtered.drop(df_filtered[rows_with_age_120].index)\n",
    "    \n",
    "    df_filtered = handle_gas_feature(df_filtered)\n",
    "    \n",
    "    df_filtered['age_income'] = df_filtered.age * df_filtered.income\n",
    "    \n",
    "    df_missing = df[rows_with_missing | rows_with_age_120]\n",
    "    \n",
    "    return df_filtered, df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering_replace(df):\n",
    "    \n",
    "    df_replaced = df.copy()\n",
    "    \n",
    "    df_replaced.drop(columns=['Unnamed: 0', 'code_column'], inplace=True)\n",
    "\n",
    "    df_replaced['housing_type'] = df_replaced['housing_type'].fillna(df_replaced['housing_type'].mode()[0])\n",
    "    \n",
    "    df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
    "    \n",
    "    df_replaced['num_vehicles'] = df_replaced['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    df_replaced['recent_move_b'] = df_replaced['recent_move_b'].fillna(df_replaced['recent_move_b'].mode()[0])\n",
    "    df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_replaced['age'] = df_replaced['age'].replace(0, df_replaced['age'].median())\n",
    "    df_replaced['age'] = df_replaced['age'].replace(120, df_replaced['age'].median())\n",
    "    \n",
    "    df_replaced = handle_gas_feature(df_replaced)\n",
    "    \n",
    "    df_replaced['age_income'] = df_replaced.age * df_replaced.income\n",
    "    \n",
    "    return df_replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION\n",
    "\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\52935028.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\52935028.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\52935028.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\52935028.py:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n"
     ]
    }
   ],
   "source": [
    "df_filtered, df_missing = apply_data_engineering(raw_data)\n",
    "sub_filtered, sub_missing = apply_data_engineering(masked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col in categorical_features or col in label_features:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in numerical_features:\n",
    "            df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_df = pd.concat([df_filtered, df_missing], axis=0, ignore_index=True)\n",
    "\n",
    "xgb_train_df.drop(columns=['custid'], inplace=True)\n",
    "\n",
    "convert_feature_types(xgb_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9049130554788849\n"
     ]
    }
   ],
   "source": [
    "#### THIS CODE IS FOR THE XGBOOST MODEL ####\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is the column you want to predict\n",
    "X = xgb_train_df.drop(target_feature, axis=1)\n",
    "y = xgb_train_df[target_feature]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "predictions = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_threshold:  0.9317484\n"
     ]
    }
   ],
   "source": [
    "X_train = xgb_train_df.drop(columns=target_feature)\n",
    "y_train = xgb_train_df[target_feature]\n",
    "\n",
    "masked_df = pd.concat([sub_filtered, sub_missing], axis=0, ignore_index=True)\n",
    "\n",
    "X_submission = masked_df.drop(columns=['custid', 'health_ins'])\n",
    "\n",
    "convert_feature_types(X_submission)\n",
    "\n",
    "X_sub_matrix = xgb.DMatrix(X_submission, enable_categorical=True)\n",
    "\n",
    "y_pred = bst.predict(X_sub_matrix)\n",
    "\n",
    "# Compute the median of the predictions\n",
    "median_threshold = np.median(y_pred)\n",
    "\n",
    "print(\"median_threshold: \", median_threshold)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "xgb_submission_df = pd.DataFrame({\n",
    "    'custid': masked_df['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Convert the numeric values in 'predicted_y' to 'TRUE' or 'FALSE' based on the median threshold\n",
    "xgb_submission_df['health_ins'] = xgb_submission_df['health_ins'].apply(lambda x: 'TRUE' if x > median_threshold else 'FALSE')\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "xgb_submission_df.to_csv('xgb_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_17180\\3637797522.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].fillna(df_replaced['recent_move_b'].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "rf_train_data = apply_data_engineering_replace(raw_data)\n",
    "rf_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "rf_train_data = preprocess_dataframe(rf_train_data, fit_preprocessor=True)\n",
    "rf_submission_data = preprocess_dataframe(rf_submission_data, fit_preprocessor=False)\n",
    "rf_submission_data['health_ins'] = rf_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features\n",
    "X = rf_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = rf_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 20, 'n_estimators': 300}\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', criterion='gini', max_depth=20, n_estimators=300)\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "rf_submission_features = rf_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = rf_model.predict(rf_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "rf_submission_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_df.to_csv('rf_submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = rf_model.predict_proba(rf_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "rf_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_balanced_df.to_csv('rf_submission_balanced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\Athos\\AppData\\Local\\Temp\\ipykernel_22912\\3637797522.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['recent_move_b'] = df_replaced['recent_move_b'].replace({'T': True, 'F': False})\n"
     ]
    }
   ],
   "source": [
    "dt_train_data = apply_data_engineering_replace(raw_data)\n",
    "dt_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "dt_train_data = preprocess_dataframe(dt_train_data, fit_preprocessor=True)\n",
    "dt_submission_data = preprocess_dataframe(dt_submission_data, fit_preprocessor=False)\n",
    "dt_submission_data['health_ins'] = dt_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features\n",
    "X = dt_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = dt_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 29, 'splitter': 'best'}\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=29, splitter='best')\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "dt_submission_features = dt_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = dt_model.predict(dt_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "dt_submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_df.to_csv('dt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = dt_model.predict_proba(dt_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "dt_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_balanced_df.to_csv('dt_submission_balanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
