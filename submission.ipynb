{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv('customer.csv')\n",
    "masked_df = pd.read_csv('customer_test_masked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_features = ['state_of_res']\n",
    "categorical_features = ['sex','housing_type', 'gas_category','is_employed']\n",
    "numerical_features = ['income', 'num_vehicles', 'age', 'gas_usage', 'rooms', 'age_income','age_vehicles','income_gas']\n",
    "target_feature = 'health_ins'\n",
    "id_feature = 'custid'\n",
    "\n",
    "# Define a preprocessor globally so it can be reused\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('label', OrdinalEncoder(), label_features),\n",
    "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('scaler', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "def preprocess_dataframe(df, fit_preprocessor=True):\n",
    "    global preprocessor  # Use the same preprocessor instance\n",
    "    \n",
    "    # Drop the target feature for feature processing\n",
    "    df_features = df.drop(target_feature, axis=1, errors='ignore')\n",
    "    \n",
    "    if fit_preprocessor:\n",
    "        # Fit and transform the preprocessor on training data\n",
    "        features_processed = preprocessor.fit_transform(df_features)\n",
    "    else:\n",
    "        # Only transform using an already fitted preprocessor\n",
    "        features_processed = preprocessor.transform(df_features)\n",
    "    \n",
    "    # Extract feature names from the preprocessor\n",
    "    feature_names = (\n",
    "        label_features +\n",
    "        preprocessor.named_transformers_['onehot'].get_feature_names_out(categorical_features).tolist() +\n",
    "        numerical_features +\n",
    "        [id_feature]\n",
    "    )\n",
    "    \n",
    "    # Create a DataFrame for the processed features\n",
    "    df_processed = pd.DataFrame(features_processed, columns=feature_names)\n",
    "    \n",
    "    # Ensure indices align\n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    df_processed['income_state'] = df_processed['income'] * df_processed['state_of_res']\n",
    "    # Add the target feature back if it exists in the original DataFrame\n",
    "    if target_feature in df.columns:\n",
    "        df_target = df[target_feature].reset_index(drop=True)\n",
    "        df_processed[target_feature] = df_target\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(X, y):\n",
    "    smote = ADASYN(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sample_then_split(df, sample_function, params, classifier):\n",
    "    # Preprocess data\n",
    "    preprocessed_df = preprocess_dataframe(df)\n",
    "\n",
    "    X = preprocessed_df.drop(target_feature, axis=1)  \n",
    "    y = preprocessed_df[target_feature]\n",
    "        \n",
    "    # Sample data\n",
    "    X_resampled, y_resampled = sample_function(X, y)\n",
    "    \n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train model with GridSearchCV\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=params, cv=5)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Best Parameters: {grid_search.best_params_}')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_gas_feature(df):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    gas_median = df_copy[df_copy['gas_usage'] > 3].gas_usage.median()\n",
    "\n",
    "    non_bill_cases_values = {\n",
    "        1: gas_median,\n",
    "        2: gas_median,\n",
    "        3: 0\n",
    "    }\n",
    "    non_bill_cases = {\n",
    "        1: 'Included in rent', \n",
    "        2: 'Included in electricity', \n",
    "        3: 'No charge'\n",
    "    }\n",
    "\n",
    "    # New feature for gas usage category\n",
    "    df_copy['gas_category'] = df_copy['gas_usage'].replace(non_bill_cases).where(\n",
    "        df_copy['gas_usage'].isin(non_bill_cases.keys()), 'Actual Bill'\n",
    "    )\n",
    "    df_copy.loc[pd.isna(df_copy['gas_usage']), 'gas_category'] = 'Unknown'\n",
    "\n",
    "    # Replace non-bill cases' values or maintain if not included\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].replace(non_bill_cases_values)\n",
    "    df_copy['gas_usage'] = df_copy['gas_usage'].fillna(gas_median)\n",
    "    df_copy['income_gas'] = df_copy['income'] * df_copy['gas_usage']\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering(df):\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    df_filtered.drop(columns=['Unnamed: 0', 'code_column','marital_status','recent_move_b'], inplace=True)\n",
    "\n",
    "    rows_with_missing = df_filtered.isnull().sum(axis=1) > 2\n",
    "    df_filtered.drop(df_filtered[rows_with_missing].index, inplace=True)\n",
    "    \n",
    "    df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
    "    \n",
    "    df_filtered['num_vehicles'] = df_filtered['num_vehicles'].fillna(round(df['num_vehicles'].mean(),0))\n",
    "    \n",
    "    # df_filtered['recent_move_b'] = df_filtered['recent_move_b'].fillna(df_filtered['recent_move_b'].mode()[0])\n",
    "    # df_filtered['recent_move_b'] = df_filtered['recent_move_b'].replace({'T': True, 'F': False})\n",
    "    \n",
    "    df_filtered['age'] = df_filtered['age'].replace(0, df_filtered['age'].median())\n",
    "    rows_with_age_120 = df_filtered['age'] == 120\n",
    "    df_filtered = df_filtered.drop(df_filtered[rows_with_age_120].index)\n",
    "    \n",
    "    df_filtered = handle_gas_feature(df_filtered)\n",
    "    \n",
    "    df_filtered['age_income'] = df_filtered.age * df_filtered.income\n",
    "    df_filtered['age_vehicles'] = df_filtered.age * df_filtered.num_vehicles\n",
    "    \n",
    "    df_missing = df[rows_with_missing | rows_with_age_120]\n",
    "    df_missing.drop(columns=['Unnamed: 0', 'code_column','marital_status','recent_move_b'], inplace=True)\n",
    "    return df_filtered, df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_data_engineering_replace(df):\n",
    "    df_replaced = df.copy()\n",
    "    \n",
    "    df_replaced.drop(columns=['Unnamed: 0', 'code_column', 'marital_status', 'recent_move_b'], inplace=True, errors='ignore')\n",
    "\n",
    "    df_replaced['housing_type'] = df_replaced['housing_type'].fillna(df_replaced['housing_type'].mode()[0])\n",
    "    df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
    "    df_replaced['num_vehicles'] = df_replaced['num_vehicles'].fillna(round(df['num_vehicles'].mean(), 0))\n",
    "    df_replaced['age'] = df_replaced['age'].replace(0, df_replaced['age'].median())\n",
    "    df_replaced['age'] = df_replaced['age'].replace(120, df_replaced['age'].median())\n",
    "    df_replaced['age'] = df_replaced['age'].fillna(df_replaced['age'].median())\n",
    "\n",
    "    df_replaced = handle_gas_feature(df_replaced)\n",
    "\n",
    "    df_replaced['age_income'] = df_replaced.age * df_replaced.income\n",
    "    df_replaced['age_vehicles'] = df_replaced.age * df_replaced.num_vehicles\n",
    "\n",
    "    return df_replaced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION\n",
    "\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\2130856372.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\2130856372.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_missing.drop(columns=['Unnamed: 0', 'code_column','marital_status','recent_move_b'], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\2130856372.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_filtered['is_employed'] = df_filtered['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\2130856372.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_missing.drop(columns=['Unnamed: 0', 'code_column','marital_status','recent_move_b'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_filtered, df_missing = apply_data_engineering(raw_data)\n",
    "sub_filtered, sub_missing = apply_data_engineering(masked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_types(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if col in categorical_features or col in label_features:\n",
    "            df[col] = df[col].astype('category')\n",
    "        elif col in numerical_features:\n",
    "            df[col] = df[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_df = pd.concat([df_filtered, df_missing], axis=0, ignore_index=True)\n",
    "\n",
    "xgb_train_df.drop(columns=['custid'], inplace=True)\n",
    "\n",
    "convert_feature_types(xgb_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9044070291655166\n"
     ]
    }
   ],
   "source": [
    "#### THIS CODE IS FOR THE XGBOOST MODEL ####\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming df is your DataFrame and 'target' is the column you want to predict\n",
    "X = xgb_train_df.drop(target_feature, axis=1)\n",
    "y = xgb_train_df[target_feature]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "predictions = [1 if pred > 0.5 else 0 for pred in preds]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = xgb_train_df.drop(columns=target_feature)\n",
    "y_train = xgb_train_df[target_feature]\n",
    "\n",
    "masked_df = pd.concat([sub_filtered, sub_missing], axis=0, ignore_index=True)\n",
    "\n",
    "X_submission = masked_df.drop(columns=['custid', 'health_ins'])\n",
    "\n",
    "convert_feature_types(X_submission)\n",
    "\n",
    "X_sub_matrix = xgb.DMatrix(X_submission, enable_categorical=True)\n",
    "\n",
    "y_pred = bst.predict(X_sub_matrix)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "xgb_submission_df = pd.DataFrame({\n",
    "    'custid': masked_df['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Convert the numeric values in 'predicted_y' to 'TRUE' or 'FALSE' based on the median threshold\n",
    "xgb_submission_df['health_ins'] = xgb_submission_df['health_ins'].apply(lambda x: 'TRUE' if x > 0.9 else 'FALSE')\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "xgb_submission_df.to_csv('xgb_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "rf_train_data = apply_data_engineering_replace(raw_data)\n",
    "rf_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "rf_train_data = preprocess_dataframe(rf_train_data, fit_preprocessor=True)\n",
    "rf_submission_data = preprocess_dataframe(rf_submission_data, fit_preprocessor=False)\n",
    "rf_submission_data['health_ins'] = rf_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features\n",
    "X = rf_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = rf_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 20, 'n_estimators': 300}\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', criterion='gini', max_depth=20, n_estimators=300,max_features=10, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "rf_submission_features = rf_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = rf_model.predict(rf_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "rf_submission_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_df.to_csv('rf_submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = rf_model.predict_proba(rf_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "rf_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': rf_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "rf_submission_balanced_df.to_csv('rf_submission_balanced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "dt_train_data = apply_data_engineering_replace(raw_data)\n",
    "dt_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "dt_train_data = preprocess_dataframe(dt_train_data, fit_preprocessor=True)\n",
    "dt_submission_data = preprocess_dataframe(dt_submission_data, fit_preprocessor=False)\n",
    "dt_submission_data['health_ins'] = dt_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features\n",
    "X = dt_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y = dt_train_data[target_feature]\n",
    "\n",
    "# define model random forest model following the best parameters {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 29, 'splitter': 'best'}\n",
    "dt_model = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=29, splitter='best')\n",
    "\n",
    "# resample data\n",
    "X_resampled, y_resampled = smote_data(X, y)\n",
    "\n",
    "# fit model\n",
    "dt_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "dt_submission_features = dt_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "# predict\n",
    "y_pred = dt_model.predict(dt_submission_features)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "dt_submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_df.to_csv('dt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED PREDICTIONS (50-50 split)\n",
    "\n",
    "# Predict probabilities (if available) for more nuanced control\n",
    "y_proba = dt_model.predict_proba(dt_submission_features)[:, 1]  # Probabilities for the positive class (True)\n",
    "\n",
    "# Sort indices by predicted probability for a deterministic split\n",
    "sorted_indices = np.argsort(y_proba)\n",
    "\n",
    "# Determine the split point\n",
    "half_count = len(y_proba) // 2\n",
    "\n",
    "# Initialize an array of predictions\n",
    "y_pred_balanced = np.zeros_like(y_proba, dtype=bool)\n",
    "\n",
    "# Set the top half to True and the bottom half to False\n",
    "y_pred_balanced[sorted_indices[:half_count]] = False\n",
    "y_pred_balanced[sorted_indices[half_count:]] = True\n",
    "\n",
    "# Create a DataFrame for the balanced predictions\n",
    "dt_submission_balanced_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column\n",
    "    'health_ins': y_pred_balanced             # Balanced predictions\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "dt_submission_balanced_df.to_csv('dt_submission_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "nn_train_data = apply_data_engineering_replace(raw_data)\n",
    "dt_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "nn_train_data = preprocess_dataframe(nn_train_data, fit_preprocessor=True)\n",
    "nn_submission_data = preprocess_dataframe(dt_submission_data, fit_preprocessor=False)\n",
    "nn_submission_data['health_ins'] = nn_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712us/step - accuracy: 0.7112 - loss: 0.5690\n",
      "Epoch 2/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687us/step - accuracy: 0.7463 - loss: 0.5121\n",
      "Epoch 3/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 654us/step - accuracy: 0.7639 - loss: 0.4831\n",
      "Epoch 4/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 636us/step - accuracy: 0.7894 - loss: 0.4356\n",
      "Epoch 5/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 642us/step - accuracy: 0.8094 - loss: 0.3987\n",
      "Epoch 6/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702us/step - accuracy: 0.8178 - loss: 0.3778\n",
      "Epoch 7/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 685us/step - accuracy: 0.8259 - loss: 0.3603\n",
      "Epoch 8/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 658us/step - accuracy: 0.8307 - loss: 0.3504\n",
      "Epoch 9/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 611us/step - accuracy: 0.8373 - loss: 0.3422\n",
      "Epoch 10/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 623us/step - accuracy: 0.8411 - loss: 0.3330\n",
      "Epoch 11/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 611us/step - accuracy: 0.8440 - loss: 0.3269\n",
      "Epoch 12/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 702us/step - accuracy: 0.8484 - loss: 0.3208\n",
      "Epoch 13/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 682us/step - accuracy: 0.8505 - loss: 0.3138\n",
      "Epoch 14/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 718us/step - accuracy: 0.8556 - loss: 0.3069\n",
      "Epoch 15/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 700us/step - accuracy: 0.8562 - loss: 0.3036\n",
      "Epoch 16/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 697us/step - accuracy: 0.8579 - loss: 0.2999\n",
      "Epoch 17/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 685us/step - accuracy: 0.8607 - loss: 0.2960\n",
      "Epoch 18/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 681us/step - accuracy: 0.8643 - loss: 0.2896\n",
      "Epoch 19/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 696us/step - accuracy: 0.8633 - loss: 0.2895\n",
      "Epoch 20/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 673us/step - accuracy: 0.8652 - loss: 0.2862\n",
      "Epoch 21/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669us/step - accuracy: 0.8665 - loss: 0.2831\n",
      "Epoch 22/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - accuracy: 0.8697 - loss: 0.2789\n",
      "Epoch 23/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 671us/step - accuracy: 0.8671 - loss: 0.2794\n",
      "Epoch 24/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 667us/step - accuracy: 0.8708 - loss: 0.2768\n",
      "Epoch 25/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 678us/step - accuracy: 0.8721 - loss: 0.2733\n",
      "Epoch 26/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 692us/step - accuracy: 0.8741 - loss: 0.2699\n",
      "Epoch 27/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 677us/step - accuracy: 0.8743 - loss: 0.2694\n",
      "Epoch 28/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 680us/step - accuracy: 0.8756 - loss: 0.2678\n",
      "Epoch 29/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 677us/step - accuracy: 0.8767 - loss: 0.2642\n",
      "Epoch 30/30\n",
      "\u001b[1m4128/4128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - accuracy: 0.8774 - loss: 0.2633\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "def create_nn_model():\n",
    "    nn = Sequential()\n",
    "    nn.add(layers.Dense(128, activation='relu', input_dim=19)) \n",
    "    nn.add(layers.Dense(64, activation='relu'))\n",
    "    nn.add(layers.Dense(32, activation='relu'))\n",
    "    nn.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "    nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return nn\n",
    "\n",
    "nn = create_nn_model()\n",
    "\n",
    "X_train = nn_train_data.drop([target_feature, id_feature], axis=1)\n",
    "y_train = nn_train_data[target_feature]\n",
    "\n",
    "X_submission = nn_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "X_respample, Y_resample = smote_data(X_train, y_train)\n",
    "\n",
    "# Convert the data to float32\n",
    "X_respample = X_respample.astype('float32')\n",
    "Y_resample = Y_resample.astype('float32')\n",
    "X_submission = X_submission.astype('float32')\n",
    "\n",
    "# Train the model\n",
    "nn.fit(X_respample, Y_resample, epochs=30, batch_size=32)\n",
    "\n",
    "y_pred = nn.predict(X_submission)\n",
    "\n",
    "y_pred = (y_pred > 0.6).astype(int)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "submission_df = pd.DataFrame({\n",
    "    'custid': dt_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred.flatten()        # Add the predicted values\n",
    "})\n",
    "\n",
    "# Convert the numeric values in 'predicted_y' to 'TRUE' and 'FALSE'\n",
    "submission_df['health_ins'] = submission_df['health_ins'].map({1: 'TRUE', 0: 'FALSE'})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "\n",
    "submission_df.to_csv('submission_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11720\\3751234964.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_replaced['is_employed'] = df_replaced['is_employed'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "knn_train_data = apply_data_engineering_replace(raw_data)\n",
    "knn_submission_data = apply_data_engineering_replace(masked_df)\n",
    "\n",
    "knn_train_data = preprocess_dataframe(knn_train_data, fit_preprocessor=True)\n",
    "knn_submission_data = preprocess_dataframe(knn_submission_data, fit_preprocessor=False)\n",
    "knn_submission_data['health_ins'] = knn_submission_data['health_ins'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "X_train = knn_train_data.drop([target_feature, id_feature], axis=1)\n",
    "\n",
    "y_train = knn_train_data[target_feature]\n",
    "\n",
    "X_submission = knn_submission_data.drop(columns=[target_feature, id_feature])\n",
    "\n",
    "X_resampled, y_resampled = smote_data(X_train, y_train)\n",
    "\n",
    "knn.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = knn.predict(X_submission)\n",
    "\n",
    "# Create a DataFrame for the predictions and the custid\n",
    "\n",
    "knn_submission_df = pd.DataFrame({\n",
    "    'custid': knn_submission_data['custid'],  # Retrieve the 'custid' column from the original DataFrame\n",
    "    'health_ins': y_pred           # Add the predicted values\n",
    "})\n",
    "\n",
    "# Store the DataFrame without column names\n",
    "knn_submission_df.to_csv('knn_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
